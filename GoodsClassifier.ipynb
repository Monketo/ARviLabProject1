{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load GoodsClassifier.py\n",
    "\n",
    "import os\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = \"data/goods_features/\"\n",
    "index_path = features_path + \"resnet_256.idx\"\n",
    "pretrained_features_path = features_path + \"finetuned_weights.h5\"\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 8\n",
    "\n",
    "# кількість класів, підставте ваше значення\n",
    "nb_classes = 844\n",
    "epochs = 42\n",
    "# розділити датасет на тренувальний та тестовий\n",
    "# у пропорції 90/10\n",
    "train_dir = '../datasets/classifieds/train'\n",
    "validation_dir = '../datasets/classifieds/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель = ResNet50 без голови з одним dense шаром для класифікації об'єктів на nb_classes\n",
    "def get_model(nb_classes=100, fine_tune=False):\n",
    "    feature_extractor = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    flat = Flatten()(feature_extractor.output)  \n",
    "    # можна додати кілька dense шарів:\n",
    "    d = Dense(nb_classes*2, activation='relu')(flat)\n",
    "    d = Dense(nb_classes, activation='softmax')(d)\n",
    "    d = Dense(nb_classes, activation='softmax')(d)\n",
    "    model = Model(inputs=feature_extractor.input, outputs=d)\n",
    "    \n",
    "    if fine_tune:\n",
    "        model.load_weights(pretrained_features_path)\n",
    "        \n",
    "    # \"заморозимо\" всі шари ResNet50, крім кількох останніх\n",
    "    # базові ознаки згорткових шарів перших рівнів досить універсальні, тому ми не будемо міняти їх ваги\n",
    "    # кількість шарів, які ми \"заморожуємо\" - це гіперпараметр    \n",
    "        for layer in m.layers[:-12]:\n",
    "            layer.trainable = False            \n",
    "    # для finetuning ми використаємо звичайний SGD з малою швидкістю навчання та моментом\n",
    "        m.compile(\n",
    "            optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    else:\n",
    "        for layer in m.layers[:-3]:\n",
    "            layer.trainable = False\n",
    "        model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_head_model(nb_classes):\n",
    "    feature_extractor = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)      \n",
    "    \n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    features_train = feature_extractor.predict_generator(\n",
    "        train_generator, nb_train_samples // batch_size)\n",
    "    \n",
    "    features_validation = feature_extractor.predict_generator(\n",
    "        validation_generator, nb_validation_samples // batch_size)\n",
    "      \n",
    "    model = get_model(nb_classes)\n",
    "    model.fit(features_train, train_generator.classes,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(features_validation, validation_generator.classes))\n",
    "    \n",
    "    model.save_weights(pretrained_features_path)\n",
    "    print(\"Pretrained features have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_finetuning(nb_classes):\n",
    "        \n",
    "    model = get_model(nb_classes, fine_tune=True)\n",
    "\n",
    "    train_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    \n",
    "    validation_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_gen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = validation_gen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    \n",
    "    model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        nb_epoch=epochs,\n",
    "        callbacks=[ModelCheckpoint(pretrained_features_path, save_best_only=True, monitor='val_loss')])\n",
    "\n",
    "    model.save_weights(pretrained_features_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startTraining(nb_classes):\n",
    "    if not os.path.exists(pretrained_features_path):\n",
    "        train_head_model(nb_classes)\n",
    "    model = start_finetuning(nb_classes)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 2048\n",
    "n_trees = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_n_neighbours(targetImagePath, topn=5):\n",
    "    annoy = AnnoyIndex(vector_size, metric='angular')\n",
    "    annoy.load(index_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
